# Report
## Part 1:
Construct an experiment to estimate the speed at which a particular computer can process an authentication password. From the estimate, determine how long it would take to test common password candidate lists, such as a list on 100 or 1000 popular passwords, the same list enhanced with orthographic substitutions (3 for e, zero for O, one for 1, 2 for z, and so forth), and a word list from a common online dictionary. There is no single right answer to this question. The point of the question is to perform the analysis to determine the number of possibilities and the rate at which those possibilities can be checked.

### Experiment: 
  We chose to write a program that reads a password or list of passwords and verifies that they meet the criteria of most passwords. The password must have at least 8 characters, it must have uppercase and lowercase letters, it must contain at least one number, it cannot contain a ‘%’ character, and it must contain one of these special characters: ? . [ ] { } - _ + * ! ~\
  \
  The program first checks the length of the password, then verifies that it doesn’t contain a ‘%’ before checking for numbers and uppercase and lowercase letters. The program finally checks for any special characters in the password, when one is found it stops looking for more because the password only needs one special character. We chose to order the tests in this way because any passwords that aren’t long enough shouldn’t need to be checked for any specific characters because we already know that it’s a bad password. Similarly, for the ‘%’ character, if one is found then there’s no reason to check the password for the other criteria because passwords cannot contain that character, so it’s a bad password. Now the program iterates through the password string and looks at each character, when a number, an uppercase letter, or a lowercase letter are found, the program stops looking for those criteria. The program then checks the characters in the password a second time to look for a special character.\
  \
  When the program first receives a password, the clock time is grabbed and stored in a variable so it can be used later to estimate how long it took to process each individual password, after the password has been determined good or bad. These values are used to create an average processing time for all of the passwords tested. When all of the passwords have been tested, the program writes that average to the console.\
  \
  The program reads values from a file, so we tested one password by writing it into a file and telling the program to read from that file. For 100 passwords, we listed 100 strings in the text file, similarly for 1000 passwords, orthographic substitutions, and a common wordlist. The common wordlist that we used contains roughly 13,330 passwords and can be found on Kenneth Navarro’s GitHub page: https://github.com/kennyn510/wpa2-wordlists/blob/master/PlainText/logins.txt 

### Results:
  Before we tested actual passwords to receive accurate estimates, we decided to attempt to come up with our own estimates to see how close we would be. We both thought that the processing times would be low for one password and would increase for each password added to the list because we would only need to test one password for the criteria, as opposed to hundreds of passwords that each go through anywhere from one to eight checks. Interestingly, we were proven wrong completely and it turns out that the opposite is true, that one password takes longer to process than many and that files containing more passwords had a lower average processing time. Parts of that make sense, like the fact that one password takes longer to process than hundreds of them because there’s not enough passwords to establish an accurate average processing time and this one could be an outlier. However, we’re unsure why processing one password takes 2.6 times longer than processing 100 passwords and two times longer than the remaining tests. That amount of time seems out of the ordinary, but even when you consider that there might be outliers and calculate an average of testing single passwords the results are nearly identical. We think that this has to do with the amount of variety in the passwords, if we included more variation in the length and special characters used we may have gotten more consistent results.\

        Average processing time for one password: 
            0.000024061589971 seconds
        Average processing time for 100 passwords:
            0.000009201472826 seconds
        Average processing time for 1000 passwords:
            0.000010062556926 seconds
        Average processing time for passwords with orthographic substitutions:
            0.000011419098056 seconds
        Average processing time for 13,300 passwords from a common wordlist:
            0.000010388381799 seconds

## Part 2:
  Discuss the algebra of authentication: Assume a situation with two-factor authentication and call the factors A and B. Considering the four cases in which each is either strong or weak, what conclusion can you draw about the result: weak A + weak B = ?, weak A + strong B = ?, etc. Does order matter, for example, is weak A + strong B = strong A + weak B? Does it matter if the two factors are of the same type, for example, two things you know? What happens if you add a third factor C? This question does not have a single right answer. You should base your discussion on analysis of examples.\
  
**Two-factor authentication**

|		  Factor A   	 |		   Factor B         |
|:------------------:|:------------------------:|
|      Weak A	     |        Weak B          |
|     Strong A	   |       Strong B         |

  **weakA + weakB =** weak authentication because using a 4-character password with a 4-digit token isn’t going to be noticeably more secure than one 4-unit authentication type. In total there are 8 characters to work with and cracking an 8-character password takes only minutes. The advantage in this case is that there are two authentication processes, which separates the two systems and may provide more security if the first system is used by more people or required lower security measures to allow more access. This is also a disadvantage because an attacker only needs to discover two 4-character passwords, which could take less time in total than one 8-character password because more passwords tend to take less time to process as we saw in question 5.

  **weakA + strongB =** weak authentication, or somewhere right in the middle of strong and weak authentication. This is not ideally how the two-factor authentication should be implemented because the weak authentication system will allow access to a larger group and the strong authentication system will filter the larger group into only those that need access. This model encourages the use of least privilege because the stronger authentication process prevents anyone that doesn’t need access, but it’s easier for an attacker to get into the larger group and hide within that group if it’s large enough. If an attacker gets through the first authentication system they have more of an opportunity to get past the stronger system than if both systems were strong. This kind of authentication could be thought of as similar to a DMZ.

  **strongA + weakB =** weak authentication because an attacker will be able to spread their influence more quickly after getting through the strong authentication system, meaning that they’ll be harder to control once they get through. This brings up the problem of an attacker on the inside, such as a rogue employee because they’re expected to get through the stronger authentication system and not the weaker one. This kind of authentication process also doesn’t encourage least privilege because it requires higher security to gain initial access so the user would need more privileges than they need.

  **strongA + strongB =** strong authentication because both authentication systems require equal levels of security and privilege. This would be ideal from a security standpoint, but the user experience would suffer because of the increased security. Even if an attacker were able to get through the first authentication system, the second would be equally as challenging which would stall the attacker even longer.

### Does order matter:
  Yes because ideally we want least privilege, so if the higher security measure is used first then the user will need higher privileges than those that are needed for the weak security measure. Even though the equations shown previously are equivalent to their inverse the order is still important because of the principle of least privilege. Stronger authentication implies that the user needs higher security clearance, so subsequent authentication systems with lower security clearance are redundant and unnecessary because the user needed higher security clearance in the first place. 
    ●	weakB + weakA = weak authentication - equivalent to weakA + weakB.
    ●	weakB + strongA = weak authentication - equivalent to strongA + weakB.
    ●	strongB + strongA = strong authentication - equivalent to strongA + strongB.
    ●	strongB + weakA = weak authentication - equivalent to weakA + strongB.

### What if A and B are the same factor:
  It’s still possible to have strong security if both factors in two-factor authentication are of the same type, for example if both are biometric authentication systems that used different parts of the body like retina and fingerprint, then the entire process is relatively secure. If the two factors are short passwords or PINs, then the authentication will be weak as discussed previously. In general, it’s always going to be more secure to use two different authentication types because an attacker hopefully wouldn’t have access to both factors in one location or object, the information needed to gain access will be separated. This means that it will take the attacker longer to gather all of that information which means they’re more likely to get caught, or the separated authentication data may even drive them away from attacking all together.

### What about 3-factor authentication? Adding a factor C:
  Adding a third factor to the authentication process would greatly enhance overall security, but the same limitations apply. If the three authentication systems all require the same weak authentication method, then the authentication will be weak overall. However, the advantage is that it’ll take an attacker longer to completely penetrate the systems so they’re more likely to be caught in the act or discovered and prevented from continuing. One serious disadvantage comes from the impact to the user experience, having to go through three entire authentication processes would be tedious and time consuming. Similar to the equations shown above, the order of these systems is even more important because any mistakes when assigning privileges would propagate through multiple systems, if an attacker could take advantage of this vulnerability they would have a much larger attack surface to work with and the point of impact would be more difficult to determine. If the three authentication methods are all strong and use different authentication types (token, password, biometric), then the authentication will be very strong but it’ll also be a tedious process. If they use the same authentication type, it’s still possible to implement strong authentication but the authentication will never be as strong as it would be if different authentication types were used. 
